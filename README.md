<p align="center"><h1>ü§ñ Getting Started</h2></p>
<p align="left"><h3>‚≠êÔ∏èJupyter Lab Guide</h3></p>

1.	Install Jupyter lab or Jupyter lab cloud  
        ‚Ä¢	 https://jupyter-batch-us-region-1.cloud.intel.com/user/u37b6cfaa417403454509c45c11d2628/lab/tree/Training/AI/GenAI<br>
 	     ‚Ä¢	 https://jupyter.org/install
       
2.	Start the server


---

<p align="left"><h3>‚≠êÔ∏èRequirements</h3></p>
1.	Stable Internet connection <br>
2.	Memory and disk space required per user: 512MB RAM + 1GB of disk + .5 CPU core.<br>
3.	Server overhead: 2-4GB or 10% system overhead (whatever is larger), .5 CPU cores, 10GB disk space.<br>

<p align="left"><h3>‚≠êÔ∏èRequired Packages</h3></p>
1.	intel-extension-for-transformers <br> <p align = "left">https://github.com/intel/intel-extension-for-transformers</p>
2.	llama-2-7-hf-b model <br><p align ="left">https://huggingface.co/meta-llama/Llama-2-7b-chat-hf</p> 
3.	Huggingface id with access token permissions "Fine grained & Write permission" <p align ="left">https://huggingface.co/</p>

<p align="left"><h3>‚≠êÔ∏èStep by step procedure to run the notebooks</h3></p>
  <h3>Terminal :</h3> <br>
  1.Create an anaconda environment:

```
       $conda create -n itrex python=3.10 -y
```
  2.Activate the environment:
```
       $conda active itrex
```
  3.Install the pip package of requirements 
```
       $pip install intel-extension-for-transformers
```
  4.Clone the following repository
```
       $git clone https://github.com/intel/intel-extension-for-transformers.git
```
  5.Install the pip package of CPU requirements
```
       $pip install -r requirements_cpu.txt
```
  6.Login with the huggingface id with a newly created access token
```
       $huggingface-cli login
```            
  7.Install the kernel for the environment
```
       $python3 -m pip install jupyter ipykernel
```
  8.Create the kernel with user permission 
```
       $python3 -m ipykernel install ‚Äìname neural-chat --user
```

<p align="left"><H4>‚Ä¢First Notebook :  build_chatbot_on_spr.ipynb</H4></p>
 1.        Select the kernel we created ‚Äúneural_chat‚Äù<br>
 2.        Run all the cells and you will get the desired output<br>
 
<p align="left"><h4>‚Ä¢Second Notebook : single_node_finetuning_on_spr.ipynb  on google collab</h4>
1.Import the notebook into google collab <br>
2.Run all the cells by selecting runtime type to CPU <br>
3.Record training time <br>

 

              
